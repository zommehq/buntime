# Plano: Infraestrutura Local de Desenvolvimento

## Ambiente de Teste

Este guia foi testado na seguinte configuração:

| Item | Valor |
|------|-------|
| Sistema | Ubuntu 24.04 LTS Server |
| RAM | 25 GB |
| CPU | 6 vCPUs |
| Disco | 80 GB |
| IP | 192.168.0.201 |
| User | djalmajr |

### Requisitos por Cenário

| Cenário | CPU | RAM | Serviços |
|---------|-----|-----|----------|
| Mínimo | 2 | 8 GB | MinIO, libSQL, Keycloak |
| Básico | 2 | 16 GB | + Rancher |
| Completo | 4+ | 24 GB | + GitLab |

### Distribuição de Recursos (6 CPU / 25GB RAM)

| Serviço | CPU Req | CPU Lim | Mem Req | Mem Lim |
|---------|---------|---------|---------|---------|
| k3s + sistema | - | - | ~2 GB | - |
| MinIO | 250m | 500m | 512 MB | 1 GB |
| libSQL Primary | 100m | 500m | 256 MB | 512 MB |
| libSQL Replica | 50m | 250m | 128 MB | 256 MB |
| Keycloak | 250m | 1000m | 1 GB | 2 GB |
| Rancher | 250m | 1000m | 1 GB | 2 GB |
| GitLab webservice | 300m | 1500m | 2 GB | 3 GB |
| GitLab sidekiq | 200m | 1000m | 1 GB | 2 GB |
| GitLab gitaly | 100m | 500m | 512 MB | 1 GB |
| GitLab postgres | 100m | 500m | 512 MB | 1 GB |
| GitLab redis | 50m | 250m | 256 MB | 512 MB |
| GitLab registry | 50m | 200m | 128 MB | 256 MB |
| GitLab outros | 100m | 300m | 256 MB | 512 MB |
| GitLab Runner | 100m | 500m | 128 MB | 256 MB |
| **Total Requests** | ~1.9 | - | ~9.75 GB | - |
| **Total Limits** | - | ~8 | - | ~16.5 GB |

## Objetivo

Configurar ambiente de desenvolvimento que simula produção com:
- Servidor Ubuntu 24 LTS (192.168.0.201)
- k3s (Kubernetes leve)
- DNS local (*.home)
- Serviços: GitLab, MinIO, Keycloak, Rancher, libSQL (com réplica)

## Arquitetura

```
┌─────────────────────────────────────────────────────────────────┐
│  Clientes (Mac/Linux/Windows)                                   │
│                                                                 │
│  DNS: *.home → 192.168.0.201                                    │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
          │
          ▼
┌─────────────────────────────────────────────────────────────────┐
│  Ubuntu 24 LTS (192.168.0.201)                                  │
│  user: djalmajr                                                 │
│                                                                 │
│  ┌────────────────────────────────────────────────────────────┐ │
│  │  k3s                                                       │ │
│  │  ┌──────────────────────────────────────────────────────┐  │ │
│  │  │  Traefik Ingress (:80, :443)                         │  │ │
│  │  │  + cert-manager (TLS self-signed)                    │  │ │
│  │  └──────────────────────────────────────────────────────┘  │ │
│  │                           │                                │ │
│  │  ┌────────────────────────▼─────────────────────────────┐  │ │
│  │  │  Namespaces                                          │  │ │
│  │  │                                                      │  │ │
│  │  │  [gitlab]     gitlab.home                            │  │ │
│  │  │  [minio]      minio.home / s3.home                   │  │ │
│  │  │  [keycloak]   keycloak.home                          │  │ │
│  │  │  [rancher]    rancher.home                           │  │ │
│  │  │  [libsql]     libsql.home (primary + replica)        │  │ │
│  │  └──────────────────────────────────────────────────────┘  │ │
│  │                                                            │ │
│  │  ┌──────────────────────────────────────────────────────┐  │ │
│  │  │  Storage: local-path-provisioner (padrão k3s)        │  │ │
│  │  │  Path: /var/lib/rancher/k3s/storage                  │  │ │
│  │  └──────────────────────────────────────────────────────┘  │ │
│  └────────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────────┘
```

---

## Fase 1: Preparar Ubuntu

### 1.1 Acesso SSH do Mac

```bash
# No Mac - configurar SSH sem senha
ssh-copy-id djalmajr@192.168.0.201

# Testar
ssh djalmajr@192.168.0.201
```

### 1.2 Atualizar sistema

```bash
# No Ubuntu
sudo apt update && sudo apt upgrade -y
sudo apt install -y curl wget git htop
```

### 1.3 Configurar hostname

```bash
sudo hostnamectl set-hostname k3s-dev
echo "192.168.0.201 k3s-dev" | sudo tee -a /etc/hosts
```

### 1.4 Desabilitar swap (requisito k8s)

```bash
sudo swapoff -a
sudo sed -i '/ swap / s/^/#/' /etc/fstab
```

---

## Fase 2: Instalar k3s

### 2.1 Instalar k3s

```bash
curl -sfL https://get.k3s.io | sh -s - \
  --write-kubeconfig-mode 644 \
  --disable traefik \
  --node-name k3s-dev
```

> Nota: Desabilitamos o Traefik padrão para instalar versão mais recente via Helm.

### 2.2 Verificar instalação

```bash
sudo kubectl get nodes
sudo kubectl get pods -A
```

### 2.3 Configurar kubectl para usuário

```bash
mkdir -p ~/.kube
sudo cp /etc/rancher/k3s/k3s.yaml ~/.kube/config
sudo chown $(id -u):$(id -g) ~/.kube/config
chmod 600 ~/.kube/config
```

### 2.4 Instalar Helm

```bash
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
```

---

## Fase 3: Configurar Ingress e TLS

### 3.1 Instalar Traefik via Helm

```bash
helm repo add traefik https://traefik.github.io/charts
helm repo update

kubectl create namespace traefik

helm install traefik traefik/traefik \
  --namespace traefik \
  --set ingressClass.enabled=true \
  --set ingressClass.isDefaultClass=true \
  --set service.type=LoadBalancer \
  --set 'ports.web.redirections.entryPoint.to=websecure' \
  --set 'ports.web.redirections.entryPoint.scheme=https' \
  --set ports.websecure.tls.enabled=true
```

### 3.2 Instalar cert-manager

```bash
kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.14.0/cert-manager.yaml

# Aguardar pods ficarem ready
kubectl wait --for=condition=Ready pods --all -n cert-manager --timeout=120s
```

### 3.3 Criar ClusterIssuer self-signed

```bash
cat <<EOF | kubectl apply -f -
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: selfsigned-issuer
spec:
  selfSigned: {}
---
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: home-ca
  namespace: cert-manager
spec:
  isCA: true
  commonName: home-ca
  secretName: home-ca-secret
  privateKey:
    algorithm: ECDSA
    size: 256
  issuerRef:
    name: selfsigned-issuer
    kind: ClusterIssuer
---
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: home-ca-issuer
spec:
  ca:
    secretName: home-ca-secret
EOF
```

---

## Fase 4: Deploy dos Serviços

### 4.1 MinIO

```bash
kubectl create namespace minio

helm repo add minio https://charts.min.io/
helm repo update

# Criar arquivo de valores (evita problemas de escaping)
cat > /tmp/minio-values.yaml << EOF
rootUser: admin
rootPassword: _MySecP4ss#87
mode: standalone
persistence:
  size: 50Gi
resources:
  requests:
    memory: 1Gi
    cpu: 250m
  limits:
    memory: 2Gi
    cpu: 1000m
ingress:
  enabled: true
  ingressClassName: traefik
  hosts:
    - minio.home
  annotations:
    cert-manager.io/cluster-issuer: home-ca-issuer
  tls:
    - secretName: minio-tls
      hosts:
        - minio.home
consoleIngress:
  enabled: true
  ingressClassName: traefik
  hosts:
    - console.minio.home
  annotations:
    cert-manager.io/cluster-issuer: home-ca-issuer
  tls:
    - secretName: minio-console-tls
      hosts:
        - console.minio.home
EOF

helm install minio minio/minio --namespace minio -f /tmp/minio-values.yaml
```

### 4.2 libSQL (Primary + Replica)

> **Nota:** Não usar `args` - a imagem libsql-server espera env vars, não argumentos de linha de comando.
>
> **Recomendação:** Instale o libSQL no mesmo namespace que o buntime (`zomme`) para simplificar a comunicação entre serviços. Se preferir namespaces separados, ajuste as URLs de acordo (ex: `http://libsql.libsql:8080`).

```bash
# Usar namespace único para todos os serviços Zomme
kubectl create namespace zomme

cat <<EOF | kubectl apply -f -
# Primary libSQL
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: libsql-primary
  namespace: zomme
spec:
  serviceName: libsql-primary
  replicas: 1
  selector:
    matchLabels:
      app: libsql
      role: primary
  template:
    metadata:
      labels:
        app: libsql
        role: primary
    spec:
      containers:
      - name: libsql
        image: ghcr.io/tursodatabase/libsql-server:latest
        ports:
        - containerPort: 8080
          name: http
        - containerPort: 5001
          name: grpc
        - containerPort: 9090
          name: admin
        env:
        - name: SQLD_NODE
          value: primary
        - name: SQLD_ENABLE_NAMESPACES
          value: "true"
        - name: SQLD_ADMIN_LISTEN_ADDR
          value: "0.0.0.0:9090"
        resources:
          requests:
            memory: 512Mi
            cpu: 100m
          limits:
            memory: 1Gi
            cpu: 500m
        volumeMounts:
        - name: data
          mountPath: /var/lib/sqld
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
---
# Replica libSQL
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: libsql-replica
  namespace: zomme
spec:
  serviceName: libsql-replica
  replicas: 1
  selector:
    matchLabels:
      app: libsql
      role: replica
  template:
    metadata:
      labels:
        app: libsql
        role: replica
    spec:
      containers:
      - name: libsql
        image: ghcr.io/tursodatabase/libsql-server:latest
        ports:
        - containerPort: 8080
          name: http
        env:
        - name: SQLD_NODE
          value: replica
        - name: SQLD_PRIMARY_URL
          value: "http://libsql-primary:5001"
        resources:
          requests:
            memory: 256Mi
            cpu: 50m
          limits:
            memory: 512Mi
            cpu: 250m
        volumeMounts:
        - name: data
          mountPath: /var/lib/sqld
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
---
# Services
apiVersion: v1
kind: Service
metadata:
  name: libsql
  namespace: zomme
spec:
  selector:
    app: libsql
    role: primary
  ports:
  - port: 8080
    targetPort: 8080
    name: http
  - port: 5001
    targetPort: 5001
    name: grpc
  - port: 9090
    targetPort: 9090
    name: admin
---
apiVersion: v1
kind: Service
metadata:
  name: libsql-replica
  namespace: zomme
spec:
  selector:
    app: libsql
    role: replica
  ports:
  - port: 8080
    targetPort: 8080
    name: http
---
# Ingress for primary (write)
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: libsql
  namespace: zomme
  annotations:
    cert-manager.io/cluster-issuer: home-ca-issuer
spec:
  ingressClassName: traefik
  tls:
  - hosts:
    - libsql.home
    secretName: libsql-tls
  rules:
  - host: libsql.home
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: libsql
            port:
              number: 8080
---
# Ingress for replica (read)
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: libsql-replica
  namespace: zomme
  annotations:
    cert-manager.io/cluster-issuer: home-ca-issuer
spec:
  ingressClassName: traefik
  tls:
  - hosts:
    - libsql-ro.home
    secretName: libsql-replica-tls
  rules:
  - host: libsql-ro.home
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: libsql-replica
            port:
              number: 8080
---
# Wildcard Certificate for namespaces (*.libsql.home)
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: libsql-wildcard
  namespace: zomme
spec:
  secretName: libsql-wildcard-tls
  issuerRef:
    name: home-ca-issuer
    kind: ClusterIssuer
  dnsNames:
  - "*.libsql.home"
  - "libsql.home"
---
# Wildcard Ingress for namespaces (e.g., skedly.libsql.home)
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: libsql-namespaces
  namespace: zomme
  annotations:
    cert-manager.io/cluster-issuer: home-ca-issuer
spec:
  ingressClassName: traefik
  tls:
  - hosts:
    - "*.libsql.home"
    secretName: libsql-wildcard-tls
  rules:
  - host: "*.libsql.home"
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: libsql
            port:
              number: 8080
EOF
```

#### Criar Namespaces (Multi-tenancy)

O Admin API do libSQL roda na porta 9090 e é **interno ao cluster** (sem Ingress) por segurança. Para criar namespaces, use `kubectl port-forward`:

```bash
# Terminal 1: Forward da porta admin
kubectl port-forward -n zomme svc/libsql 9090:9090

# Terminal 2: Criar namespace
curl -X POST http://localhost:9090/v1/namespaces/meu-app/create \
  -H "Content-Type: application/json" \
  -d '{}'
```

Após criar, o namespace fica acessível via wildcard Ingress:
- URL: `https://meu-app.libsql.home`

**Outros comandos do Admin API:**

```bash
# Deletar namespace
curl -X DELETE http://localhost:9090/v1/namespaces/meu-app

# Fork namespace (clonar)
curl -X POST http://localhost:9090/v1/namespaces/origem/fork/destino
```

> **Nota:** O Admin API não possui autenticação própria. A segurança é garantida por estar acessível apenas via `kubectl`, que requer credenciais do cluster.

#### Conectar via DBeaver

O DBeaver possui driver nativo para libSQL. Para conectar:

1. Nova Conexão > LibSQL
2. Server URL: `https://libsql.home`
3. Token: (deixar vazio se não configurou autenticação)

**Erro de certificado SSL:**

Se aparecer erro `unable to find valid certification path to requested target`, importe o CA no keystore do Java do DBeaver:

```bash
# Exportar CA do cluster
kubectl get secret home-ca-secret -n cert-manager -o jsonpath='{.data.ca\.crt}' | base64 -d > ~/home-ca.crt

# Importar no Java do DBeaver (macOS)
sudo keytool -import -trustcacerts \
  -alias home-ca \
  -file ~/home-ca.crt \
  -keystore "/Applications/DBeaver.app/Contents/Eclipse/jre/Contents/Home/lib/security/cacerts" \
  -storepass changeit -noprompt
```

Reinicie o DBeaver após importar.

> **Nota:** Após atualizar o DBeaver, pode ser necessário reimportar o certificado pois a atualização pode sobrescrever o keystore.

### 4.3 Keycloak

> **Nota:** Bitnami moveu para modelo pago. Usar imagem oficial.

```bash
kubectl create namespace keycloak

cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: keycloak
  namespace: keycloak
spec:
  replicas: 1
  selector:
    matchLabels:
      app: keycloak
  template:
    metadata:
      labels:
        app: keycloak
    spec:
      containers:
      - name: keycloak
        image: quay.io/keycloak/keycloak:26.0
        args: ["start-dev"]
        env:
        - name: KC_BOOTSTRAP_ADMIN_USERNAME
          value: admin
        - name: KC_BOOTSTRAP_ADMIN_PASSWORD
          value: _MySecP4ss#87
        - name: KC_PROXY_HEADERS
          value: xforwarded
        - name: KC_HOSTNAME_URL
          value: https://keycloak.home
        - name: KC_HOSTNAME_ADMIN_URL
          value: https://keycloak.home
        - name: KC_HOSTNAME_STRICT
          value: "false"
        - name: KC_HTTP_ENABLED
          value: "true"
        - name: JAVA_OPTS_APPEND
          value: "-Xms512m -Xmx1536m"
        ports:
        - containerPort: 8080
          name: http
        resources:
          requests:
            memory: 1Gi
            cpu: 250m
          limits:
            memory: 2Gi
            cpu: 1000m
---
apiVersion: v1
kind: Service
metadata:
  name: keycloak
  namespace: keycloak
spec:
  selector:
    app: keycloak
  ports:
  - port: 8080
    targetPort: 8080
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: keycloak
  namespace: keycloak
  annotations:
    cert-manager.io/cluster-issuer: home-ca-issuer
spec:
  ingressClassName: traefik
  tls:
  - hosts:
    - keycloak.home
    secretName: keycloak-tls
  rules:
  - host: keycloak.home
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: keycloak
            port:
              number: 8080
EOF
```

### 4.4 GitLab

> **Requisitos:** Mínimo 8GB RAM livre, 4+ CPUs. Recomendado 24GB RAM e 6 CPUs.
> **Nota ARM64:** O MinIO bundled do GitLab não suporta ARM64. Usar MinIO externo.

```bash
kubectl create namespace gitlab

helm repo add gitlab https://charts.gitlab.io/
helm repo update

# Criar secrets para conexão com MinIO externo
cat > /tmp/gitlab-rails-storage.yaml << EOF
provider: AWS
region: us-east-1
aws_access_key_id: admin
aws_secret_access_key: _MySecP4ss#87
endpoint: http://minio.minio.svc.cluster.local:9000
path_style: true
EOF

cat > /tmp/gitlab-backups-storage.yaml << EOF
[default]
aws_access_key_id = admin
aws_secret_access_key = _MySecP4ss#87
EOF

kubectl create secret generic gitlab-rails-storage -n gitlab \
  --from-file=connection=/tmp/gitlab-rails-storage.yaml

kubectl create secret generic gitlab-backups-storage -n gitlab \
  --from-file=config=/tmp/gitlab-backups-storage.yaml

# Criar secret para senha root
kubectl create secret generic gitlab-root-password -n gitlab \
  --from-literal=password='_MySecP4ss#87'

# Criar arquivo de valores (ARM64 compatible)
cat > /tmp/gitlab-values.yaml << 'EOF'
global:
  hosts:
    domain: home
    externalIP: 192.168.0.201
  edition: ce
  # Senha root fixa
  initialRootPassword:
    secret: gitlab-root-password
    key: password
  ingress:
    class: traefik
    configureCertmanager: false
    annotations:
      cert-manager.io/cluster-issuer: home-ca-issuer
  # Usar MinIO externo (ARM64 compatible)
  minio:
    enabled: false
  appConfig:
    # Object storage desabilitado para artifacts (evita problemas com MinIO)
    # Artifacts usam filesystem local, outros recursos usam MinIO
    object_store:
      enabled: false
    artifacts:
      enabled: false  # Usa filesystem local
    lfs:
      enabled: true
      bucket: gitlab-lfs
      connection:
        secret: gitlab-rails-storage
        key: connection
    uploads:
      enabled: true
      bucket: gitlab-uploads
      connection:
        secret: gitlab-rails-storage
        key: connection
    packages:
      enabled: true
      bucket: gitlab-packages
      connection:
        secret: gitlab-rails-storage
        key: connection
    backups:
      bucket: gitlab-backups

certmanager:
  installCRDs: false

nginx-ingress:
  enabled: false

prometheus:
  install: false

gitlab-runner:
  install: false

registry:
  enabled: false

gitlab:
  webservice:
    minReplicas: 1
    maxReplicas: 1
    resources:
      requests:
        memory: 2Gi
        cpu: 300m
      limits:
        memory: 3Gi
        cpu: 1500m
  sidekiq:
    minReplicas: 1
    maxReplicas: 1
    resources:
      requests:
        memory: 1Gi
        cpu: 200m
      limits:
        memory: 2Gi
        cpu: 1000m
  gitlab-shell:
    minReplicas: 1
    maxReplicas: 1
    resources:
      requests:
        memory: 64Mi
        cpu: 10m
      limits:
        memory: 128Mi
        cpu: 100m
  gitaly:
    resources:
      requests:
        memory: 512Mi
        cpu: 100m
      limits:
        memory: 1Gi
        cpu: 500m
  toolbox:
    backups:
      objectStorage:
        config:
          secret: gitlab-backups-storage
          key: config
    resources:
      requests:
        memory: 64Mi
        cpu: 10m
      limits:
        memory: 128Mi
        cpu: 100m
  kas:
    minReplicas: 1
    maxReplicas: 1
    resources:
      requests:
        memory: 64Mi
        cpu: 10m
      limits:
        memory: 128Mi
        cpu: 100m

postgresql:
  resources:
    requests:
      memory: 512Mi
      cpu: 100m
    limits:
      memory: 1Gi
      cpu: 500m

redis:
  resources:
    requests:
      memory: 256Mi
      cpu: 50m
    limits:
      memory: 512Mi
      cpu: 250m
EOF

helm install gitlab gitlab/gitlab \
  --namespace gitlab \
  --timeout 15m \
  -f /tmp/gitlab-values.yaml
```

**Obter senha root após instalação:**

```bash
kubectl get secret gitlab-gitlab-initial-root-password -n gitlab \
  -o jsonpath='{.data.password}' | base64 -d; echo
```

### 4.5 Rancher

> **Nota:** Usar `ingress.tls.source=rancher` para certificados self-signed sem configurar CA manualmente.

```bash
kubectl create namespace cattle-system

helm repo add rancher-stable https://releases.rancher.com/server-charts/stable
helm repo update

helm install rancher rancher-stable/rancher \
  --namespace cattle-system \
  --set hostname=rancher.home \
  --set replicas=1 \
  --set bootstrapPassword=_MySecP4ss#87 \
  --set ingress.tls.source=rancher
```

#### 4.5.1 Configurar hostAliases para GitLab

Para que o Rancher consiga acessar o GitLab (para Helm charts), adicione hostAliases:

```bash
kubectl patch deployment rancher -n cattle-system --type=strategic -p '{
  "spec": {
    "template": {
      "spec": {
        "hostAliases": [
          {
            "ip": "192.168.0.201",
            "hostnames": ["gitlab.home", "registry.gitlab.home"]
          }
        ]
      }
    }
  }
}'
```

#### 4.5.2 Adicionar Helm Charts Registry do GitLab

Para usar Helm charts hospedados no GitLab:

```bash
# 1. Tornar o grupo e repo públicos (se necessário)
curl -sk -X PUT "https://gitlab.home/api/v4/groups/5" \
  -H "PRIVATE-TOKEN: $GITLAB_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"visibility": "public"}'

curl -sk -X PUT "https://gitlab.home/api/v4/projects/2" \
  -H "PRIVATE-TOKEN: $GITLAB_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"visibility": "public"}'

# 2. Criar ClusterRepo no Rancher
cat <<EOF | kubectl apply -f -
apiVersion: catalog.cattle.io/v1
kind: ClusterRepo
metadata:
  name: zomme
spec:
  gitRepo: https://gitlab.home/zomme/charts.git
  gitBranch: main
  insecureSkipTLSVerify: true
EOF

# 3. Verificar sync
kubectl get clusterrepo zomme -o jsonpath='{.status.conditions}' | jq
```

> **Nota:** `insecureSkipTLSVerify: true` é necessário porque o GitLab usa certificado self-signed.

### 4.6 GitLab Container Registry

> **Nota:** O registry usa MinIO externo para storage e é acessível via `https://registry.gitlab.home`.

#### 4.6.1 Criar bucket no MinIO

```bash
# Criar bucket para o registry
kubectl run minio-mc --restart=Never -n minio \
  --image=minio/mc:latest \
  --command -- sh -c "mc alias set minio http://minio:9000 admin '_MySecP4ss#87' && mc mb minio/gitlab-registry --ignore-existing"

# Aguardar e verificar
sleep 10 && kubectl logs minio-mc -n minio && kubectl delete pod minio-mc -n minio
```

#### 4.6.2 Criar secret para storage

> **Importante:** O `redirect: disable: true` é necessário para que o registry não redirecione pulls para a URL interna do MinIO (que não é acessível externamente).

```bash
cat > /tmp/registry-storage.yaml << 'EOF'
s3:
  bucket: gitlab-registry
  accesskey: admin
  secretkey: _MySecP4ss#87
  region: us-east-1
  regionendpoint: http://minio.minio.svc.cluster.local:9000
  v4auth: true
  secure: false
  rootdirectory: /
redirect:
  disable: true
EOF

kubectl create secret generic gitlab-registry-storage -n gitlab \
  --from-file=config=/tmp/registry-storage.yaml

rm /tmp/registry-storage.yaml
```

#### 4.6.3 Habilitar registry via Helm upgrade

```bash
cat > /tmp/gitlab-registry-values.yaml << 'EOF'
global:
  hosts:
    domain: gitlab.home
    gitlab:
      name: gitlab.home
    registry:
      name: registry.gitlab.home
    kas:
      name: kas.gitlab.home

registry:
  enabled: true
  storage:
    secret: gitlab-registry-storage
    key: config
  ingress:
    enabled: true
    class: traefik
    annotations:
      cert-manager.io/cluster-issuer: home-ca-issuer
    tls:
      secretName: gitlab-registry-tls
  resources:
    requests:
      memory: 128Mi
      cpu: 50m
    limits:
      memory: 256Mi
      cpu: 200m
EOF

helm upgrade gitlab gitlab/gitlab \
  --namespace gitlab \
  --reuse-values \
  -f /tmp/gitlab-registry-values.yaml \
  --timeout 10m
```

#### 4.6.4 Copiar CA secret para namespace gitlab

O GitLab instala seu próprio cert-manager no namespace `gitlab`. Para que o ClusterIssuer `home-ca-issuer` funcione, é necessário copiar o secret `home-ca-secret` do namespace `cert-manager` para `gitlab`:

```bash
kubectl get secret home-ca-secret -n cert-manager -o yaml | \
  sed 's/namespace: cert-manager/namespace: gitlab/' | \
  kubectl apply -f -
```

#### 4.6.5 Verificar instalação

```bash
# Verificar pods
kubectl get pods -n gitlab | grep registry

# Verificar ingress
kubectl get ingress -n gitlab | grep registry

# Testar endpoint (deve retornar UNAUTHORIZED - é esperado)
curl -sk https://registry.gitlab.home/v2/
```

#### 4.6.6 Configurar Docker Desktop (macOS/Windows)

Como o registry usa certificado self-signed, é necessário configurar o Docker para confiar nele.

**Editar `~/.docker/daemon.json`:**

```json
{
  "insecure-registries": [
    "registry.gitlab.home",
    "gitlab.home"
  ]
}
```

**Reiniciar Docker Desktop** após a alteração.

#### 4.6.7 Usar o registry

```bash
# Login (usar credenciais do GitLab)
docker login registry.gitlab.home -u root -p '_MySecP4ss#87'

# Build e push
docker build -t registry.gitlab.home/zomme/minha-app:latest .
docker push registry.gitlab.home/zomme/minha-app:latest

# Pull
docker pull registry.gitlab.home/zomme/minha-app:latest
```

### 4.7 GitLab Runner (Kubernetes Executor)

> **Nota:** O runner usa executor Kubernetes e roda jobs como pods no namespace `gitlab-runner`.

#### 4.7.1 Criar namespace e recursos RBAC

```bash
kubectl create namespace gitlab-runner

cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ServiceAccount
metadata:
  name: gitlab-runner
  namespace: gitlab-runner
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: gitlab-runner
  namespace: gitlab-runner
rules:
- apiGroups: [""]
  resources: ["pods", "pods/exec", "pods/attach", "pods/log", "secrets", "configmaps"]
  verbs: ["get", "list", "watch", "create", "delete", "update", "patch"]
- apiGroups: [""]
  resources: ["services"]
  verbs: ["get", "list", "watch", "create", "delete"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: gitlab-runner
  namespace: gitlab-runner
subjects:
- kind: ServiceAccount
  name: gitlab-runner
  namespace: gitlab-runner
roleRef:
  kind: Role
  name: gitlab-runner
  apiGroup: rbac.authorization.k8s.io
EOF
```

#### 4.7.2 Obter token de registro do runner

No GitLab, acesse **Admin Area > CI/CD > Runners** e copie o token de registro, ou crie via API:

```bash
# Criar runner via API (substitua o token)
GITLAB_TOKEN="glpat-xxxxx"

curl -sk -X POST "https://gitlab.home/api/v4/user/runners" \
  -H "PRIVATE-TOKEN: $GITLAB_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "runner_type": "instance_type",
    "tag_list": ["docker", "kubernetes"],
    "description": "Kubernetes Runner"
  }' | jq '.token'
```

#### 4.7.3 Criar ConfigMap do runner

```bash
# Substitua RUNNER_TOKEN pelo token obtido
RUNNER_TOKEN="glrt-xxxxx"

cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: gitlab-runner-config
  namespace: gitlab-runner
data:
  config.toml: |
    concurrent = 4
    check_interval = 3
    shutdown_timeout = 0

    [session_server]
      session_timeout = 1800

    [[runners]]
      name = "kubernetes-runner"
      url = "https://gitlab.home/"
      clone_url = "https://gitlab.home/"
      token = "${RUNNER_TOKEN}"
      executor = "kubernetes"
      tls-ca-file = "/etc/gitlab-runner/certs/ca.crt"
      environment = ["GIT_SSL_NO_VERIFY=1", "DOCKER_HOST=tcp://docker:2375", "DOCKER_TLS_CERTDIR="]
      [runners.kubernetes]
        namespace = "gitlab-runner"
        service_account = "gitlab-runner"
        image = "docker:24"
        helper_image = "gitlab/gitlab-runner-helper:arm64-v18.8.0"
        privileged = true
        pull_policy = ["if-not-present"]
        [[runners.kubernetes.host_aliases]]
          ip = "192.168.0.201"
          hostnames = ["gitlab.home", "kas.gitlab.home", "registry.gitlab.home"]
      [runners.kubernetes.node_selector]
        "kubernetes.io/os" = "linux"
EOF
```

> **Nota ARM64:** Se seu cluster for ARM64, use `helper_image = "gitlab/gitlab-runner-helper:arm64-v18.8.0"`. Para x86_64, remova essa linha ou use a imagem padrão.

#### 4.7.4 Deploy do runner

```bash
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: gitlab-runner
  namespace: gitlab-runner
spec:
  replicas: 1
  selector:
    matchLabels:
      app: gitlab-runner
  template:
    metadata:
      labels:
        app: gitlab-runner
    spec:
      serviceAccountName: gitlab-runner
      hostAliases:
      - ip: "192.168.0.201"
        hostnames:
        - gitlab.home
        - kas.gitlab.home
        - registry.gitlab.home
      containers:
      - name: gitlab-runner
        image: gitlab/gitlab-runner:latest
        command: ["gitlab-runner", "run", "--working-directory=/tmp"]
        env:
        - name: GIT_SSL_NO_VERIFY
          value: "1"
        securityContext:
          runAsUser: 0
        volumeMounts:
        - name: config
          mountPath: /etc/gitlab-runner
          readOnly: true
        - name: ca-cert
          mountPath: /etc/gitlab-runner/certs
          readOnly: true
      volumes:
      - name: config
        configMap:
          name: gitlab-runner-config
      - name: ca-cert
        secret:
          secretName: gitlab-wildcard-tls-ca
          items:
          - key: cfssl_ca
            path: ca.crt
EOF
```

#### 4.7.5 Verificar runner

```bash
# Ver pod do runner
kubectl get pods -n gitlab-runner

# Ver logs do runner
kubectl logs -n gitlab-runner -l app=gitlab-runner

# Verificar no GitLab: Admin Area > CI/CD > Runners
```

---

## Fase 5: Configurar DNS nos Clientes

### 5.1 macOS

```bash
# Instalar dnsmasq
brew install dnsmasq

# Configurar resolução
echo "address=/.home/192.168.0.201" >> $(brew --prefix)/etc/dnsmasq.conf

# Criar resolver do macOS
sudo mkdir -p /etc/resolver
echo "nameserver 127.0.0.1" | sudo tee /etc/resolver/home

# Iniciar serviço
sudo brew services start dnsmasq

# Testar
ping gitlab.home
dig gitlab.home @127.0.0.1
```

### 5.2 Linux (Ubuntu/Debian)

**Opção A: systemd-resolved (recomendado)**

```bash
# Criar arquivo de configuração
sudo mkdir -p /etc/systemd/resolved.conf.d
sudo tee /etc/systemd/resolved.conf.d/home.conf << EOF
[Resolve]
DNS=192.168.0.201
Domains=~home
EOF

# Reiniciar resolved
sudo systemctl restart systemd-resolved

# Testar
resolvectl query gitlab.home
```

**Opção B: dnsmasq**

```bash
# Instalar
sudo apt install dnsmasq

# Configurar
echo "address=/.home/192.168.0.201" | sudo tee -a /etc/dnsmasq.conf

# Configurar NetworkManager para usar dnsmasq
sudo tee /etc/NetworkManager/conf.d/dnsmasq.conf << EOF
[main]
dns=dnsmasq
EOF

# Reiniciar serviços
sudo systemctl restart dnsmasq
sudo systemctl restart NetworkManager

# Testar
ping gitlab.home
```

**Opção C: /etc/hosts (simples, manual)**

```bash
# Adicionar entradas manualmente
sudo tee -a /etc/hosts << EOF
192.168.0.201 gitlab.home
192.168.0.201 minio.home
192.168.0.201 console.minio.home
192.168.0.201 keycloak.home
192.168.0.201 rancher.home
192.168.0.201 libsql.home
192.168.0.201 libsql-ro.home
EOF
```

### 5.3 Windows 11

**Opção A: Adicionar ao arquivo hosts (simples)**

1. Abrir Notepad como Administrador
2. Arquivo > Abrir: `C:\Windows\System32\drivers\etc\hosts`
3. Adicionar no final:

```
192.168.0.201 gitlab.home
192.168.0.201 minio.home
192.168.0.201 console.minio.home
192.168.0.201 keycloak.home
192.168.0.201 rancher.home
192.168.0.201 libsql.home
192.168.0.201 libsql-ro.home
```

4. Salvar e fechar
5. Abrir PowerShell como Admin e executar:

```powershell
ipconfig /flushdns
```

**Opção B: Acrylic DNS Proxy (wildcard *.home)**

1. Baixar e instalar:
   - Link: https://mayakron.altervista.org/support/acrylic/Home.htm
   - Executar instalador como Admin
   - Instalar com opções padrão

2. Parar o serviço (PowerShell como Admin):

```powershell
net stop "Acrylic DNS Proxy"
```

3. Configurar wildcard (PowerShell como Admin):

```powershell
notepad "C:\Program Files (x86)\Acrylic DNS Proxy\AcrylicHosts.txt"
```

Adicionar no final do arquivo:

```
# Dev Environment - Wildcard *.home
192.168.0.201 *.home
```

Salvar (Ctrl+S) e fechar.

4. Configurar DNS upstream (PowerShell como Admin):

```powershell
notepad "C:\Program Files (x86)\Acrylic DNS Proxy\AcrylicConfiguration.ini"
```

Procurar seção `[GlobalSection]` e modificar:

```ini
PrimaryServerAddress=8.8.8.8
SecondaryServerAddress=1.1.1.1
```

Salvar (Ctrl+S) e fechar.

5. Reiniciar serviço (PowerShell como Admin):

```powershell
net start "Acrylic DNS Proxy"
```

6. Configurar adaptador de rede (PowerShell como Admin):

```powershell
# Listar adaptadores
Get-NetAdapter | Where-Object {$_.Status -eq "Up"} | Select-Object Name

# Configurar DNS (substituir "Ethernet" pelo nome do seu adaptador)
Set-DnsClientServerAddress -InterfaceAlias "Ethernet" -ServerAddresses ("127.0.0.1","8.8.8.8")

# Limpar cache DNS
ipconfig /flushdns
```

7. Testar (PowerShell):

```powershell
nslookup gitlab.home
nslookup qualquercoisa.home  # wildcard
ping gitlab.home
```

8. Verificar WSL2:

```bash
# No WSL2
cat /etc/resolv.conf
ping gitlab.home
curl -k https://keycloak.home
```

Se WSL2 não resolver, criar resolv.conf manual:

```bash
# No WSL2
sudo tee /etc/wsl.conf << 'EOF'
[network]
generateResolvConf = false
EOF

# Descobrir IP do Windows
ip route | grep default

# Criar resolv.conf (substituir 172.x.x.x pelo gateway)
sudo rm /etc/resolv.conf
sudo tee /etc/resolv.conf << 'EOF'
nameserver 172.x.x.x
nameserver 8.8.8.8
EOF
```

Reiniciar WSL:

```powershell
# No PowerShell
wsl --shutdown
wsl
```

**Opção C: PowerShell (temporário, por sessão)**

```powershell
# Adiciona ao cache DNS local (não persiste após reinício)
Add-DnsClientNrptRule -Namespace ".home" -NameServers "192.168.0.201"

# Ver regras
Get-DnsClientNrptRule

# Remover
Get-DnsClientNrptRule | Where-Object Namespace -eq ".home" | Remove-DnsClientNrptRule
```

---

## Fase 6: Configurar kubectl no Mac

### 6.1 Copiar kubeconfig

```bash
scp djalmajr@192.168.0.201:~/.kube/config ~/.kube/k3s-home-config

# Ajustar IP no arquivo
sed -i '' 's/127.0.0.1/192.168.0.201/' ~/.kube/k3s-home-config
```

### 6.2 Usar contexto

```bash
export KUBECONFIG=~/.kube/k3s-home-config
kubectl get nodes
kubectl get pods -A
```

---

## Fase 7: Confiar nos certificados

### 7.1 Exportar CA do cluster

```bash
kubectl get secret home-ca-secret -n cert-manager -o jsonpath='{.data.ca\.crt}' | base64 -d > home-ca.crt
```

### 7.2 macOS

```bash
sudo security add-trusted-cert -d -r trustRoot -k /Library/Keychains/System.keychain home-ca.crt
```

### 7.3 Linux

```bash
sudo cp home-ca.crt /usr/local/share/ca-certificates/home-ca.crt
sudo update-ca-certificates
```

### 7.4 Windows 11

1. Duplo clique no arquivo `home-ca.crt`
2. Instalar Certificado
3. Máquina Local > Avançar
4. Colocar todos os certificados no repositório: "Autoridades de Certificação Raiz Confiáveis"
5. Concluir

Ou via PowerShell (Admin):

```powershell
Import-Certificate -FilePath "home-ca.crt" -CertStoreLocation Cert:\LocalMachine\Root
```

---

## URLs Finais

| Serviço | URL | Credenciais |
|---------|-----|-------------|
| GitLab | https://gitlab.home | root / _MySecP4ss#87 |
| MinIO Console | https://console.minio.home | admin / _MySecP4ss#87 |
| MinIO API | https://minio.home | admin / _MySecP4ss#87 |
| Keycloak | https://keycloak.home | admin / _MySecP4ss#87 |
| Rancher | https://rancher.home | admin / _MySecP4ss#87 |
| libSQL (write) | https://libsql.home | - |
| libSQL (read) | https://libsql-ro.home | - |
| libSQL (namespaces) | https://{namespace}.libsql.home | - |
| libSQL Admin API | http://libsql:9090 | interno k8s (namespace zomme) |
| GitLab Registry | https://registry.gitlab.home | (usa credenciais GitLab) |
| GitLab KAS | https://kas.gitlab.home | (agentes Kubernetes) |

> **Nota:** O GitLab mantém a senha original pois o reset via rails console requer mais recursos.
> Para alterar, use a interface web: Admin Area > Users > root > Edit > Password.

---

## Comandos Úteis

```bash
# Ver todos os pods
kubectl get pods -A

# Ver ingresses
kubectl get ingress -A

# Ver logs de um pod
kubectl logs -n gitlab -l app=webservice -f

# Reiniciar deployment
kubectl rollout restart deployment -n minio minio

# Ver uso de recursos
kubectl top nodes
kubectl top pods -A

# Ver certificados
kubectl get certificates -A
kubectl get certificaterequests -A
```

---

## Requisitos de Hardware

| Recurso | Mínimo | Recomendado |
|---------|--------|-------------|
| CPU | 4 cores | 8 cores |
| RAM | 16 GB | 32 GB |
| Disco | 100 GB | 200 GB SSD |

> GitLab sozinho consome ~8GB RAM. Considere desabilitar se recursos forem limitados.

---

## Problemas Encontrados Durante Instalação

### 1. SSH - Host key verification failed
**Problema:** Primeira conexão SSH falha por host desconhecido.
**Solução:**
```bash
ssh-keyscan -H 192.168.0.201 >> ~/.ssh/known_hosts
```

### 2. SSH - Chave não reconhecida automaticamente
**Problema:** `ssh-copy-id` copiou chave com nome não padrão (`id_ed25519_tm`), SSH não tenta automaticamente.
**Solução:** Copiar chave com nome padrão:
```bash
sshpass -p 'PASSWORD' ssh-copy-id -i ~/.ssh/id_rsa.pub djalmajr@192.168.0.201
```

### 3. Traefik - Parâmetro redirectTo mudou
**Problema:** `ports.web.redirectTo.port` não existe mais no chart.
**Solução:** Usar novo formato:
```bash
--set 'ports.web.redirections.entryPoint.to=websecure'
--set 'ports.web.redirections.entryPoint.scheme=https'
```

### 4. MinIO - Request de memória muito alto (16Gi)
**Problema:** Chart MinIO pede 16GB de RAM por padrão, causando `Insufficient memory`.
**Solução:** Adicionar no values.yaml:
```yaml
resources:
  requests:
    memory: 512Mi
```

### 5. Bitnami - Imagens pagas/não encontradas
**Problema:** Desde Agosto 2025, Bitnami moveu para modelo pago. Imagens como `bitnami/keycloak` não existem mais.
**Solução:** Usar imagens oficiais:
```yaml
# Em vez de bitnami/keycloak, usar:
image: quay.io/keycloak/keycloak:26.0
```

### 6. libSQL - Args inválidos no entrypoint
**Problema:** `--enable-bottomless-replication` causa erro no entrypoint do container.
**Solução:** Remover args e usar apenas env vars:
```yaml
env:
- name: SQLD_PRIMARY_URL
  value: "http://libsql-primary:5001"
```

### 7. GitLab - Requer 8GB+ RAM
**Problema:** GitLab CE precisa de no mínimo 8GB RAM, inviável em servidores pequenos.
**Solução:** Usar servidor com mais RAM ou considerar alternativas (Gitea, Forgejo).

### 8. Rancher - Secret tls-ca não existe
**Problema:** Instalação com `ingress.tls.source=secret --set privateCA=true` espera um secret `tls-ca` que não foi criado.
**Erro:** `MountVolume.SetUp failed for volume "tls-ca-volume" : secret "tls-ca" not found`
**Solução:** Usar certificado self-signed do próprio Rancher:
```bash
helm install rancher rancher-stable/rancher \
  --namespace cattle-system \
  --set hostname=rancher.home \
  --set replicas=1 \
  --set bootstrapPassword=_MySecP4ss#87 \
  --set ingress.tls.source=rancher
```

### 9. GitLab MinIO - Incompatível com ARM64
**Problema:** O MinIO bundled do GitLab chart usa imagem x86, causando `exec format error` em ARM64.
**Erro:** `exec /usr/bin/docker-entrypoint.sh: exec format error`
**Solução:** Desabilitar MinIO interno e usar MinIO externo:
```yaml
global:
  minio:
    enabled: false
  appConfig:
    object_store:
      enabled: true
      connection:
        secret: gitlab-rails-storage
        key: connection
```
E criar secrets para conexão com MinIO externo (ver seção 4.4).

### 10. GitLab - Parâmetro certmanager.install não existe
**Problema:** Tentar usar `--set certmanager.install=false` causa erro de schema validation.
**Erro:** `values don't meet the specifications of the schema(s): certmanager: additional properties 'install' not allowed`
**Solução:** Usar apenas `certmanager.installCRDs`:
```yaml
certmanager:
  installCRDs: false
```

### 11. GitLab - Object storage obrigatório
**Problema:** Com `global.minio.enabled=false`, GitLab exige configuração explícita de object storage.
**Erro:** `When consolidated object storage is enabled, for each item 'bucket' must be specified`
**Solução:** Configurar buckets e connection secret:
```yaml
global:
  appConfig:
    object_store:
      enabled: true
      connection:
        secret: gitlab-rails-storage
        key: connection
    lfs:
      bucket: gitlab-lfs
    artifacts:
      bucket: gitlab-artifacts
```

### 12. GitLab - Insufficient CPU
**Problema:** Com apenas 2 vCPUs, pods ficam em Pending por falta de CPU.
**Erro:** `0/1 nodes are available: 1 Insufficient cpu`
**Solução:** Usar no mínimo 4 vCPUs, ou reduzir drasticamente os requests de CPU:
```yaml
gitlab:
  webservice:
    resources:
      requests:
        cpu: 300m  # em vez de 500m
```

### 13. GitLab - Conflito de CRDs do cert-manager
**Problema:** Se cert-manager já está instalado, o GitLab tenta importar CRDs existentes e falha.
**Erro:** `CustomResourceDefinition "certificaterequests.cert-manager.io" exists and cannot be imported`
**Solução:** Desabilitar instalação de CRDs:
```yaml
certmanager:
  installCRDs: false
```

### 14. GitLab - Job certmanager-startupapicheck falha
**Problema:** Com cert-manager externo, o job de verificação pode falhar por timeout.
**Erro:** `job gitlab-certmanager-startupapicheck failed: BackoffLimitExceeded`
**Solução:** Garantir que cert-manager esteja 100% ready antes de instalar GitLab:
```bash
kubectl wait --for=condition=Ready pods --all -n cert-manager --timeout=120s
```

### 15. Rancher - bootstrapPassword não persiste
**Problema:** O `bootstrapPassword` do Rancher só é usado no primeiro acesso. Depois o usuário é forçado a mudar a senha, que fica persistida no banco.
**Erro:** Login com a senha configurada no Helm falha.
**Solução:** Usar `reset-password` para obter senha temporária e depois mudar via API:
```bash
# Reset para senha temporária
kubectl -n cattle-system exec $(kubectl -n cattle-system get pods -l app=rancher -o name | head -1) -- reset-password

# Mudar via API (senha deve ter 12+ caracteres, evitar ! no shell)
TOKEN=$(curl -sk "https://rancher.home/v3-public/localProviders/local?action=login" \
  -H "Content-Type: application/json" \
  -d '{"username":"admin","password":"SENHA_TEMPORARIA"}' | grep -oP '"token":"[^"]*' | cut -d\" -f4)

curl -sk "https://rancher.home/v3/users?action=changepassword" \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"currentPassword":"SENHA_TEMPORARIA","newPassword":"NOVA_SENHA_12_CHARS"}'
```

### 16. Keycloak - Mixed Content (HTTP/HTTPS)
**Problema:** Keycloak atrás de TLS termination (Traefik) gera URLs HTTP, causando erros de Mixed Content e CSP violations no browser.
**Erro:**
- `Mixed Content: The page at '<URL>' was loaded over HTTPS, but requested an insecure resource '<URL>'`
- `Framing 'http://keycloak.home/' violates Content Security Policy directive: "frame-src 'self'"`
**Solução:** Configurar variáveis de ambiente para proxy HTTPS:
```yaml
env:
- name: KC_PROXY_HEADERS
  value: xforwarded
- name: KC_HOSTNAME_URL
  value: https://keycloak.home
- name: KC_HOSTNAME_ADMIN_URL
  value: https://keycloak.home
- name: KC_HOSTNAME_STRICT
  value: "false"
- name: KC_HTTP_ENABLED
  value: "true"
```

### 17. GitLab Registry - Storage connection error
**Problema:** Registry não consegue conectar ao MinIO.
**Erro:** `level=error msg="error authorizing context" err="s3aws: AccessDenied"`
**Solução:** Verificar secret de storage:
```bash
# Verificar secret existe
kubectl get secret gitlab-registry-storage -n gitlab

# Verificar conteúdo do secret
kubectl get secret gitlab-registry-storage -n gitlab -o jsonpath='{.data.config}' | base64 -d

# Verificar conectividade com MinIO
kubectl run test-minio --rm -it --restart=Never -n gitlab \
  --image=curlimages/curl -- curl -s http://minio.minio.svc.cluster.local:9000/minio/health/live
```

### 18. GitLab Runner - Job pods não conseguem resolver DNS
**Problema:** Jobs falham porque pods não conseguem resolver `gitlab.home` ou `registry.gitlab.home`.
**Erro:** `dial tcp: lookup gitlab.home: no such host`
**Solução:** Adicionar hostAliases no ConfigMap do runner:
```toml
[[runners.kubernetes.host_aliases]]
  ip = "192.168.0.201"
  hostnames = ["gitlab.home", "kas.home", "registry.home"]
```
E também no Deployment do runner:
```yaml
hostAliases:
- ip: "192.168.0.201"
  hostnames:
  - gitlab.home
  - kas.home
  - registry.home
```

### 19. GitLab Runner - Docker build falha com TLS error
**Problema:** Docker-in-Docker não consegue fazer push para registry com certificado self-signed.
**Erro:** `x509: certificate signed by unknown authority`
**Solução:** Usar `--insecure-registry` no DinD:
```yaml
services:
  - name: docker:24-dind
    alias: docker
    command: ["--tls=false", "--insecure-registry=registry.gitlab.home"]
```
E desabilitar TLS no Docker:
```yaml
variables:
  DOCKER_TLS_CERTDIR: ""
  DOCKER_HOST: tcp://docker:2375
```

### 20. GitLab Runner - Helper image incompatível com ARM64
**Problema:** Em clusters ARM64, o helper image padrão é x86 e falha.
**Erro:** `exec format error`
**Solução:** Especificar helper image ARM64 no config.toml:
```toml
[runners.kubernetes]
  helper_image = "gitlab/gitlab-runner-helper:arm64-v18.8.0"
```

### 21. GitLab cert-manager - ClusterIssuer não encontra secret
**Problema:** Quando GitLab instala seu próprio cert-manager (namespace `gitlab`), o ClusterIssuer `home-ca-issuer` não encontra o secret `home-ca-secret` que está no namespace `cert-manager`.
**Erro:** `Error getting keypair for CA issuer: secrets "home-ca-secret" not found`
**Causa:** O cert-manager do GitLab tem o leader lease e procura secrets apenas no namespace `gitlab`.
**Solução:** Copiar o secret para o namespace `gitlab`:
```bash
kubectl get secret home-ca-secret -n cert-manager -o yaml | \
  sed 's/namespace: cert-manager/namespace: gitlab/' | \
  kubectl apply -f -
```

### 22. GitLab Registry - Redirect para MinIO interno falha
**Problema:** Ao fazer `docker pull`, o registry redireciona para URL interna do MinIO que não é acessível externamente.
**Erro:** `dial tcp: lookup minio.minio.svc.cluster.local: no such host`
**Solução:** Desabilitar redirect no storage config:
```bash
cat <<'EOF' | kubectl apply -f -
apiVersion: v1
kind: Secret
metadata:
  name: gitlab-registry-storage
  namespace: gitlab
type: Opaque
stringData:
  config: |
    s3:
      bucket: gitlab-registry
      accesskey: admin
      secretkey: "_MySecP4ss#87"
      region: us-east-1
      regionendpoint: http://minio.minio.svc.cluster.local:9000
      v4auth: true
      secure: false
      rootdirectory: /
    redirect:
      disable: true
EOF

kubectl rollout restart deployment/gitlab-registry -n gitlab
```

### 23. GitLab CI - Jobs ficam travados em "running"
**Problema:** Jobs completam no runner mas GitLab não atualiza o status. Runner fica em loop "Submitting job to coordinator...accepted, but not yet completed".
**Causa:** Sidekiq não consegue salvar trace chunks no MinIO (senha com caracteres especiais causa `SignatureDoesNotMatch`).
**Solução:** Desabilitar object storage para artifacts (usar filesystem):
```bash
cat > /tmp/gitlab-no-object-storage.yaml << 'EOF'
global:
  appConfig:
    object_store:
      enabled: false
    artifacts:
      enabled: false
EOF

helm upgrade gitlab gitlab/gitlab \
  --namespace gitlab \
  --reuse-values \
  -f /tmp/gitlab-no-object-storage.yaml \
  --timeout 10m
```

### 24. Docker - Registry com certificado self-signed
**Problema:** Docker não confia no certificado self-signed do registry.
**Erro:** `x509: certificate signed by unknown authority`
**Solução:** Adicionar registry como insecure no Docker Desktop (`~/.docker/daemon.json`):
```json
{
  "insecure-registries": [
    "registry.gitlab.home",
    "gitlab.home"
  ]
}
```
Reiniciar Docker Desktop após a alteração.

### 25. Rancher ClusterRepo - Could not resolve host
**Problema:** Rancher não consegue clonar repo Git do GitLab porque não resolve `gitlab.home`.
**Erro:** `fatal: unable to access 'https://gitlab.home/...': Could not resolve host: gitlab.home`
**Solução:** Adicionar hostAliases no deployment do Rancher:
```bash
kubectl patch deployment rancher -n cattle-system --type=strategic -p '{
  "spec": {
    "template": {
      "spec": {
        "hostAliases": [
          {
            "ip": "192.168.0.201",
            "hostnames": ["gitlab.home", "registry.gitlab.home"]
          }
        ]
      }
    }
  }
}'
```
Após o patch, recriar o ClusterRepo para forçar novo sync:
```bash
kubectl delete clusterrepo zomme
kubectl apply -f - <<EOF
apiVersion: catalog.cattle.io/v1
kind: ClusterRepo
metadata:
  name: zomme
spec:
  gitRepo: https://gitlab.home/zomme/charts.git
  gitBranch: main
  insecureSkipTLSVerify: true
EOF
```

---

## Troubleshooting

### DNS não resolve

```bash
# macOS - verificar dnsmasq
sudo brew services list | grep dnsmasq
cat /etc/resolver/home

# Linux - verificar resolved
resolvectl status
systemctl status systemd-resolved

# Windows - limpar cache
ipconfig /flushdns
nslookup gitlab.home
```

### Certificado não confiável

```bash
# Verificar se CA foi criado
kubectl get secret home-ca-secret -n cert-manager

# Verificar certificados dos ingresses
kubectl get certificates -A
kubectl describe certificate -n minio minio-tls
```

### Pod não inicia

```bash
# Ver eventos
kubectl describe pod <pod-name> -n <namespace>

# Ver logs
kubectl logs <pod-name> -n <namespace>

# Ver recursos disponíveis
kubectl describe node k3s-dev
```
