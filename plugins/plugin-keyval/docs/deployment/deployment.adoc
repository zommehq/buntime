:toc: left
:toclevels: 3
:sectnums:
:sectnumlevels: 5
:icons: font
:source-highlighter: highlightjs

== Deployment

=== Docker Compose com libSQL

O KeyVal usa libSQL (sqld) como backend de armazenamento. O sqld é o servidor HTTP/WebSocket do libSQL, adequado tanto para desenvolvimento quanto produção.

[source,yaml]
----
# docker-compose.yml
services:
  libsql:
    image: ghcr.io/tursodatabase/libsql-server:latest
    ports:
      - "8880:8080"
    volumes:
      - libsql-data:/var/lib/sqld
    environment:
      - SQLD_NODE=primary

volumes:
  libsql-data:
----

Inicie o servidor:

[source,bash]
----
docker compose up -d libsql
docker compose logs -f libsql
----

Configure o plugin no `buntime.jsonc`:

[source,jsonc]
----
{
  "plugins": [
    ["@buntime/plugin-database", {
      "adapter": {
        "type": "libsql",
        "urls": ["http://localhost:8880"]
      }
    }],
    "@buntime/plugin-keyval"
  ]
}
----

==== Testando a Conexão

Verifique se o plugin está funcionando:

[source,bash]
----
# Health check
curl http://localhost:4000/api/keyval/health

# Set value
curl -X POST http://localhost:4000/api/keyval/set \
  -H "Content-Type: application/json" \
  -d '{"key": "test", "value": "hello"}'

# Get value
curl http://localhost:4000/api/keyval/get/test
----

=== Produção com libSQL Self-Hosted

==== Configuração Segura

Em produção, o libSQL não deve ser exposto diretamente. O plugin-keyval atua como camada de abstração e segurança:

[source]
----
┌─────────────────┐      ┌──────────────────────┐      ┌─────────────────┐
│   Clients       │─────▶│  plugin-keyval       │─────▶│  libSQL (sqld)  │
│                 │ HTTP │  (/api/keyval)  │ HTTP │  (rede interna) │
└─────────────────┘      └──────────────────────┘      └─────────────────┘
----

Configure o Docker Compose para isolar o libSQL:

[source,yaml]
----
# docker-compose.yml
services:
  buntime:
    build: .
    ports:
      - "4000:4000"  # Apenas o runner é exposto
    environment:
      - LIBSQL_URL_0=http://libsql:8080
    networks:
      - internal
    depends_on:
      - libsql

  libsql:
    image: ghcr.io/tursodatabase/libsql-server:latest
    # SEM ports: expostos publicamente!
    volumes:
      - libsql-data:/var/lib/sqld
    environment:
      - SQLD_NODE=primary
    networks:
      - internal

networks:
  internal:
    internal: true  # Rede isolada, não acessível externamente

volumes:
  libsql-data:
----

==== Autenticação do sqld

Para adicionar autenticação ao sqld, configure um token JWT:

[source,yaml]
----
services:
  libsql:
    image: ghcr.io/tursodatabase/libsql-server:latest
    environment:
      - SQLD_NODE=primary
      - SQLD_AUTH_JWT_KEY=${LIBSQL_JWT_KEY}  # Chave para validar tokens
----

Gere um token JWT para o plugin:

[source,bash]
----
# Gerar chave (guarde em local seguro)
openssl rand -base64 32 > libsql-jwt-key.txt

# Configurar no ambiente
export LIBSQL_JWT_KEY=$(cat libsql-jwt-key.txt)
export LIBSQL_TOKEN=$(jwt encode --secret $LIBSQL_JWT_KEY '{}')
----

Configure o plugin com o token:

[source,jsonc]
----
{
  "plugins": [
    ["@buntime/plugin-database", {
      "adapter": {
        "type": "libsql",
        "urls": ["http://libsql:8080"],
        "authToken": "${LIBSQL_TOKEN}"
      }
    }],
    "@buntime/plugin-keyval"
  ]
}
----

TIP: Para mais detalhes sobre autenticação do sqld, consulte https://github.com/tursodatabase/libsql/blob/main/docs/AUTH.md[documentação oficial].

=== Replicação

Para configurar réplicas libSQL e escalar leituras horizontalmente, consulte a documentação do link:../../../plugin-database/docs/adapters/libsql-replication.adoc[@buntime/plugin-database] que inclui:

- Arquitetura primary + replicas
- Fluxo de operações de leitura/escrita
- Configuração de múltiplas réplicas
- Load balancing e consistência eventual

=== Considerações de Escala

==== Limites de Conexão

O sqld gerencia conexões internas automaticamente. Para workloads de alta concorrência:

1. **Connection pooling**: O plugin usa HTTP client (stateless)
2. **Cache local**: Considere adicionar Redis na frente
3. **Sharding**: Particione dados em múltiplos databases

==== Quando Considerar Sharding

Considere sharding quando:

- **Writes > 1000/s**: Primary não escala verticalmente
- **Storage > 100 GB**: SQLite tem limite prático ~1 TB
- **Hot keys**: Algumas chaves recebem muito tráfego

Estratégias de sharding:

[source,typescript]
----
// Sharding por hash do key
const shard = hashCode(key) % NUM_SHARDS;
const kv = getKVForShard(shard);
await kv.set(key, value);

// Sharding por prefixo
const shard = key.split(":")[0]; // Ex: "user:123" → shard "user"
const kv = getKVForShard(shard);
await kv.set(key, value);
----

=== Backup e Recuperação

==== Backup de Arquivo libSQL

Para self-hosted, faça backup do arquivo `.db`:

[source,bash]
----
# Backup manual
cp /var/lib/sqld/data.db /backups/data-$(date +%Y%m%d).db

# Backup automático (cron diário)
0 2 * * * cp /var/lib/sqld/data.db /backups/data-$(date +\%Y\%m\%d).db
----

TIP: Use `VACUUM INTO` para criar backup consistente sem travar writes:

[source,sql]
----
VACUUM INTO '/backups/data.db';
----

==== Restauração de Backup

Para restaurar de um backup:

[source,bash]
----
# 1. Pare o sqld
docker compose stop libsql

# 2. Restaure o arquivo
cp /backups/data-20250115.db /var/lib/sqld/data.db

# 3. Reinicie
docker compose start libsql

# 4. Valide os dados
curl http://localhost:4000/api/keyval/keys/count
----

WARNING: Restauração sobrescreve dados atuais. Sempre valide em ambiente separado antes.

=== Monitoramento em Produção

==== Prometheus Scraping

O plugin expõe métricas no endpoint `/metrics/prometheus`:

[source,yaml]
----
# prometheus.yml
scrape_configs:
  - job_name: 'buntime-keyval'
    scrape_interval: 15s
    static_configs:
      - targets: ['localhost:4000']
    metrics_path: '/api/metrics/prometheus'
----

Métricas disponíveis:

[source]
----
# Latência de operações (P50, P95, P99)
keyval_operation_duration_ms{operation="get",percentile="p95"}

# Taxa de erro
keyval_operation_errors_total{operation="set",error="conflict"}

# Tamanho da DLQ
keyval_dlq_size

# Queue processing
keyval_queue_processing_duration_ms
keyval_queue_items_processed_total
----

==== Health Check Endpoint

Configure health checks no load balancer:

[source,bash]
----
# Health check básico
curl http://localhost:4000/api/keyval/health

# Resposta OK:
{"status":"ok","timestamp":"2025-01-15T10:30:00Z"}

# Resposta com erro:
{"status":"error","error":"Connection refused","timestamp":"2025-01-15T10:30:00Z"}
----

Configure no Kubernetes:

[source,yaml]
----
livenessProbe:
  httpGet:
    path: /api/keyval/health
    port: 4000
  initialDelaySeconds: 10
  periodSeconds: 30

readinessProbe:
  httpGet:
    path: /api/keyval/health
    port: 4000
  initialDelaySeconds: 5
  periodSeconds: 10
----

==== Thresholds de Alerta

Configure alertas no Prometheus:

[source,yaml]
----
# alerts.yml
groups:
  - name: keyval
    interval: 30s
    rules:
      # DLQ está crescendo (possível backlog)
      - alert: KeyValDLQHigh
        expr: keyval_dlq_size > 100
        for: 5m
        annotations:
          summary: "DLQ size is {{ $value }}"
          description: "Dead Letter Queue has {{ $value }} items"

      # Latência P95 alta
      - alert: KeyValHighLatency
        expr: keyval_operation_duration_ms{percentile="p95"} > 100
        for: 5m
        annotations:
          summary: "P95 latency is {{ $value }}ms"

      # Taxa de erro alta
      - alert: KeyValHighErrorRate
        expr: rate(keyval_operation_errors_total[5m]) > 0.01
        for: 2m
        annotations:
          summary: "Error rate is {{ $value }}/s"

      # Database unreachable
      - alert: KeyValDatabaseDown
        expr: up{job="buntime-keyval"} == 0
        for: 1m
        annotations:
          summary: "KeyVal database is unreachable"
----

==== Dashboards no Grafana

Métricas úteis para dashboard:

1. **Operações por segundo** (QPS):
+
[source,promql]
----
rate(keyval_operations_total[5m])
----

2. **Latência (P50, P95, P99)**:
+
[source,promql]
----
keyval_operation_duration_ms{percentile=~"p50|p95|p99"}
----

3. **Taxa de erro**:
+
[source,promql]
----
rate(keyval_operation_errors_total[5m]) / rate(keyval_operations_total[5m])
----

4. **Tamanho da DLQ**:
+
[source,promql]
----
keyval_dlq_size
----

5. **Queue processing rate**:
+
[source,promql]
----
rate(keyval_queue_items_processed_total[5m])
----

=== Opções de Configuração

==== Todas as Opções do buntime.jsonc

[source,jsonc]
----
{
  "plugins": [
    [
      "@buntime/plugin-database",
      {
        "adapter": {
          "type": "libsql",
          "authToken": "${LIBSQL_TOKEN}"
        }
      }
    ],
    [
      "@buntime/plugin-keyval",
      {
        // === Queue ===
        "queue": {
          // Intervalo de limpeza de locks expirados (ms)
          "cleanupInterval": 60000,      // Padrão: 1 minuto

          // Duração do lock de processamento (ms)
          "lockDuration": 30000          // Padrão: 30 segundos
        },

        // === Métricas ===
        "metrics": {
          // Persistir métricas no database
          "persistent": true,            // Padrão: false

          // Intervalo de flush das métricas (ms)
          "flushInterval": 10000         // Padrão: 10 segundos
        }
      }
    ]
  ]
}
----

==== queue.cleanupInterval

Controla com que frequência o plugin reseta locks expirados de mensagens presas em processamento.

[cols="1,2"]
|===
| Valor | Comportamento

| `60000` (padrão)
| Cleanup a cada 1 minuto

| `300000`
| Cleanup a cada 5 minutos (menos overhead)

| `10000`
| Cleanup a cada 10 segundos (mais agressivo)
|===

NOTE: Mensagens processadas com sucesso são deletadas imediatamente (não são afetadas pelo cleanup). Mensagens que falharam são movidas para a DLQ.

TIP: Use valores maiores (5-10 minutos) em produção para reduzir carga no database.

==== queue.lockDuration

Tempo máximo que um worker pode processar um item antes de liberar o lock.

[cols="1,2"]
|===
| Valor | Comportamento

| `30000` (padrão)
| Lock de 30 segundos (tarefas rápidas)

| `300000`
| Lock de 5 minutos (tarefas longas)

| `5000`
| Lock de 5 segundos (tarefas muito rápidas)
|===

Escolha baseado na duração esperada do processamento:

[source,typescript]
----
// Tarefa rápida (< 5s) → lockDuration: 10000
kv.enqueue("send-email", { to: "user@example.com" });

// Tarefa longa (> 1min) → lockDuration: 300000
kv.enqueue("generate-report", { year: 2025 });
----

IMPORTANT: Se o processamento exceder `lockDuration`, outro worker pode pegar o mesmo item (duplicação).

==== metrics.persistent

Define se métricas são persistidas no database ou mantidas apenas em memória.

[cols="1,2"]
|===
| Valor | Comportamento

| `false` (padrão)
| Métricas apenas em memória (perdidas ao reiniciar)

| `true`
| Métricas persistidas no database (sobrevivem reinícios)
|===

Quando usar `persistent: true`:

- **Ambiente de produção**: Para não perder métricas ao fazer deploy
- **Análise histórica**: Para manter métricas de longo prazo
- **Compliance**: Quando logs/métricas são requeridos por auditoria

Quando usar `persistent: false`:

- **Desenvolvimento**: Menos overhead, mais rápido
- **High-throughput**: Evita writes extras no database
- **Prometheus/Grafana**: Se métricas já são coletadas externamente

==== metrics.flushInterval

Controla com que frequência métricas em memória são persistidas no database (se `persistent: true`).

[cols="1,2"]
|===
| Valor | Comportamento

| `10000` (padrão)
| Flush a cada 10 segundos

| `60000`
| Flush a cada 1 minuto (menos writes)

| `1000`
| Flush a cada 1 segundo (mais granular)
|===

Trade-offs:

- **Intervalo menor**: Métricas mais atualizadas, mais carga no database
- **Intervalo maior**: Menos carga, risco de perder métricas em crash

[source,jsonc]
----
{
  "plugins": [
    [
      "@buntime/plugin-keyval",
      {
        "metrics": {
          "persistent": true,
          "flushInterval": 30000  // Flush a cada 30s (balanceado)
        }
      }
    ]
  ]
}
----

TIP: Para produção, use `flushInterval: 30000` (30 segundos) como compromisso entre granularidade e performance.

=== Exemplo de Configuração Completa em Produção

[source,jsonc]
----
{
  "required": ["@buntime/plugin-metrics", "@buntime/plugin-database", "@buntime/plugin-keyval"],
  "plugins": [
    "@buntime/plugin-metrics",
    [
      "@buntime/plugin-database",
      {
        "adapter": {
          "type": "libsql",
          "authToken": "${LIBSQL_TOKEN}"
        }
      }
    ],
    [
      "@buntime/plugin-keyval",
      {
        // Queue otimizada para produção
        "queue": {
          "cleanupInterval": 300000,     // 5 minutos
          "lockDuration": 60000          // 1 minuto (tarefas médias)
        },

        // Métricas persistentes
        "metrics": {
          "persistent": true,
          "flushInterval": 30000         // 30 segundos
        }
      }
    ]
  ]
}
----

[source,bash]
----
# Variáveis de ambiente
export LIBSQL_URL_0="http://libsql:8080"
export LIBSQL_URL_1="http://libsql-replica:8080"  # Opcional
export LIBSQL_TOKEN="seu-token-jwt"

# Iniciar runner
bun run runtime/index.ts
----
