== KeyVal Roadmap

Este documento descreve o histórico de implementação do KeyVal e possíveis melhorias futuras.

=== Status de Implementação

Todas as funcionalidades planejadas foram implementadas:

[cols="1,1,2"]
|===
| Feature | Status | Implementação

| Operações CRUD básicas
| ✅ Implementado
| `kv.ts`: get, getMany, set, delete, list

| Chaves compostas
| ✅ Implementado
| string, number, bigint, boolean, Uint8Array

| TTL/Expiração automática
| ✅ Implementado
| `expireIn` option com cleanup automático

| getMany otimizado
| ✅ Implementado
| Batch SQL em uma única query

| Operações atômicas
| ✅ Implementado
| `atomic.ts`: check + mutations com versionstamp

| Mutadores atômicos
| ✅ Implementado
| sum, max, min, append, prepend

| Transações Read-Write
| ✅ Implementado
| `transaction.ts`: snapshot isolation

| Filas de mensagens
| ✅ Implementado
| `queue.ts`: retry/backoff configurável

| Watch (SSE + Polling)
| ✅ Implementado
| Backpressure e reconnection automático

| Métricas Prometheus
| ✅ Implementado
| `metrics.ts`: `/metrics/prometheus`

| Consistency modes
| ✅ Implementado
| strong/eventual com replica support

| Resiliência de conexão
| ✅ Implementado
| `connection.ts`: retry, health check, failover

| Validação de input
| ✅ Implementado
| `validation.ts`: keys, depth, length, BigInt

| Dead Letter Queue
| ✅ Implementado
| `queue.ts`: list, requeue, delete, purge

| Timeouts configuráveis
| ✅ Implementado
| `operationTimeout` com AbortSignal

| Watch por prefixo
| ✅ Implementado
| `/watch/prefix` SSE + polling

| Atomic HTTP endpoint
| ✅ Implementado
| `POST /atomic` com transações SQL

| Métricas persistentes
| ✅ Implementado
| `metrics.ts`: flush periódico para DB

| Limpeza configurável
| ✅ Implementado
| `cleanupInterval`, `maxAge`, `lockDuration`

| Triggers
| ✅ Implementado
| `kv.addTrigger()`: callbacks em `set`/`delete`

| Queue Listener
| ✅ Implementado
| `kv.queue.listen()`: processamento automático com concurrency
|===

---

=== Arquitetura Implementada

==== Conexão e Resiliência

[source,typescript]
----
// connection.ts
interface ConnectionConfig {
  maxRetries?: number;        // default: 3
  retryDelay?: number;        // default: 1000ms (exponential backoff)
  healthCheckInterval?: number; // default: 30000ms
  operationTimeout?: number;  // default: 30000ms
}
----

* Retry automático com exponential backoff e jitter
* Health checks periódicos do primary
* Failover automático para replica em leituras
* Detecção de erros transientes (network, 503, 502, 504)

==== Validação de Input

[source,typescript]
----
// validation.ts
validateKeyPath(path)     // depth max 20, part max 1024 chars
validateKeyArray(key)     // tipos permitidos
validateBatchSize(keys)   // max 1000 keys
validateBigInt(value)     // safe integer range
validateExpireIn(ms)      // positive number
validateLimit(n, min, max)
----

==== Dead Letter Queue

[source]
----
GET  /queue/dlq              - Listar mensagens
GET  /queue/dlq/:id          - Obter mensagem específica
POST /queue/dlq/:id/requeue  - Reprocessar mensagem
DELETE /queue/dlq/:id        - Deletar mensagem
DELETE /queue/dlq            - Purgar todas
----

==== Watch por Prefixo

[source]
----
GET /watch/prefix?prefix=users     - SSE stream
GET /watch/prefix/poll?prefix=users - Single request
----

==== Métricas Persistentes

[source,typescript]
----
interface MetricsConfig {
  persistent?: boolean;     // salvar em DB
  flushInterval?: number;   // default: 30000ms
}
----

---

=== Limitações Conhecidas

[cols="1,3"]
|===
| Limitação | Mitigação

| Watch por polling
| CPU intensivo com muitos watchers; use batch quando possível

| Sem autenticação própria
| Depende do Buntime AuthN/AuthZ plugins

| Dados não criptografados
| Use filesystem encryption ou Turso com TLS
|===

---

=== Possíveis Melhorias Futuras

Estas são ideias para versões futuras, não planejadas ativamente.

==== Performance

===== Query Caching

Cache de leituras frequentes em memória.

**Problema atual:**
Leituras repetidas da mesma chave sempre vão ao banco, mesmo quando o valor não mudou.

**Solução proposta:**
[source,typescript]
----
interface CacheConfig {
  enabled?: boolean;        // default: false
  maxSize?: number;         // default: 1000 entries
  ttl?: number;             // default: 5000ms
  strategy?: 'lru' | 'lfu'; // default: 'lru'
}

const kv = new Kv(adapter, {
  cache: { enabled: true, maxSize: 5000, ttl: 10000 }
});
----

**Comportamento:**

* Cache LRU/LFU em memória para `get` e `getMany`
* Invalidação automática em `set`, `delete`, e operações atômicas
* Bypass do cache com `{ consistency: 'strong' }`
* Métricas: `cache_hits`, `cache_misses`, `cache_evictions`

**Invalidação:**
[source,typescript]
----
// Invalidação local
await kv.set(["users", 1], data);  // Invalida cache local

// Invalidação cross-instance (via watch)
// Outros instances recebem evento e invalidam
----

**Complexidade:** Média - Cache local é simples, mas invalidação cross-instance requer coordenação via watch.

---

==== Funcionalidades

===== TTL por Namespace

Expiração configurada por prefixo.

**Problema atual:**
TTL deve ser especificado em cada `set()`. Não há como definir política de expiração para um namespace inteiro.

**Solução proposta:**
[source,typescript]
----
// Configuração de namespace
await kv.configureNamespace(["cache"], {
  defaultTtl: 3600000,       // 1 hora
  maxTtl: 86400000,          // 24 horas (limite)
  allowOverride: true,       // Permite TTL menor no set()
});

// Uso - TTL aplicado automaticamente
await kv.set(["cache", "user:123"], userData);
// Expira em 1 hora

// Override permitido
await kv.set(["cache", "temp"], data, { expireIn: 60000 });
// Expira em 1 minuto
----

**Armazenamento:**
[source,sql]
----
CREATE TABLE kv_namespace_config (
  prefix BLOB PRIMARY KEY,
  default_ttl INTEGER,
  max_ttl INTEGER,
  allow_override INTEGER DEFAULT 1,
  created_at INTEGER NOT NULL,
  updated_at INTEGER NOT NULL
);
----

**Comportamento:**

* Lookup de configuração no `set()` (com cache em memória)
* Validação de `maxTtl` - erro se exceder
* Herança de configuração para sub-prefixos
* API para listar/remover configurações

**Complexidade:** Baixa - Apenas lookup adicional no set() com cache.

---

==== Observabilidade

===== Distributed Tracing

Integração com OpenTelemetry.

**Problema atual:**
Métricas existem, mas não há como correlacionar operações KeyVal com traces de aplicação.

**Solução proposta:**
[source,typescript]
----
import { trace } from "@opentelemetry/api";

const kv = new Kv(adapter, {
  tracing: {
    enabled: true,
    serviceName: "keyval",
    sampler: 0.1,  // 10% das operações
  }
});

// Spans criados automaticamente
// keyval.get, keyval.set, keyval.atomic, etc.
----

**Atributos do span:**
[source]
----
db.system: "keyval"
db.operation: "get" | "set" | "delete" | "list" | "atomic"
db.keyval.key: "users/123"  -- Key como string
db.keyval.key_depth: 2
db.keyval.consistency: "strong" | "eventual"
db.keyval.cache_hit: true | false
----

**Propagação:**

* Context propagation via headers HTTP
* Parent span herdado do request
* Child spans para operações de banco

**Complexidade:** Média - Integração com OTel SDK, instrumentação de todas as operações.

---

===== Query Logging

Log de queries lentas.

**Problema atual:**
Não há visibilidade sobre quais operações estão demorando ou sendo chamadas com frequência.

**Solução proposta:**
[source,typescript]
----
const kv = new Kv(adapter, {
  queryLog: {
    enabled: true,
    slowThreshold: 100,     // ms - loga queries > 100ms
    logAll: false,          // true para logar todas
    destination: "file",    // "file" | "console" | "callback"
    filePath: "/var/log/keyval-queries.log",
  }
});
----

**Formato do log:**
[source,json]
----
{
  "timestamp": "2024-01-15T10:30:00.000Z",
  "operation": "list",
  "key": ["users"],
  "duration_ms": 150,
  "rows_affected": 500,
  "consistency": "eventual",
  "cache_hit": false,
  "sql": "SELECT * FROM kv_entries WHERE key >= ? AND key < ? LIMIT 1000"
}
----

**Análise:**

* Endpoint `/debug/slow-queries` com top N queries lentas
* Agregação por operação e prefixo
* Rotação automática de logs

**Complexidade:** Baixa - Wrapper em torno das operações existentes.

---

===== Dashboard Pré-configurado

Grafana JSON para importar.

**Problema atual:**
Métricas Prometheus existem, mas usuário precisa criar dashboard manualmente.

**Solução proposta:**

Arquivo `grafana-dashboard.json` com:

**Painéis incluídos:**

[cols="1,2"]
|===
| Painel | Métricas

| Operations/sec
| `rate(keyval_operations_total[5m])`

| Latency P50/P95/P99
| `histogram_quantile(0.95, keyval_operation_duration_ms_bucket)`

| Error Rate
| `rate(keyval_errors_total[5m])`

| Cache Hit Rate
| `keyval_cache_hits / (keyval_cache_hits + keyval_cache_misses)`

| Queue Depth
| `keyval_queue_pending + keyval_queue_processing`

| DLQ Size
| `keyval_queue_dlq`

| Connection Pool
| `keyval_pool_connections_active`, `keyval_pool_connections_idle`

| Storage Size
| `keyval_storage_bytes`
|===

**Alertas pré-configurados:**

* Error rate > 1% por 5 minutos
* P99 latency > 500ms por 5 minutos
* DLQ size > 100 mensagens
* Queue processing time > 1 hora

**Distribuição:**

* Arquivo JSON no repositório: `packages/keyval/grafana-dashboard.json`
* Importável via Grafana UI ou provisioning
* Variáveis para customização: `$datasource`, `$namespace`

**Complexidade:** Baixa - Apenas criação do JSON, sem código.
